{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSN Bootcamp Qualification Hackathon Qualification\n",
    "### Car Price Prediction Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.base import clone\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "CURRENT_YEAR = 2024\n",
    "N_SPLITS = 5\n",
    "SEED = RANDOM_STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = SEED) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "def rmse(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_advanced_engine_features(engine_str):\n",
    "    if pd.isna(engine_str) or engine_str == \"\":\n",
    "        return 0.0, 0.0, 0, 0, 0, 0\n",
    "    s = str(engine_str).upper()\n",
    "    hp = 0.0\n",
    "    for pattern in [r'(\\d+\\.?\\d*)\\s*HP', r'(\\d+\\.?\\d*)\\s*HORSEPOWER']:\n",
    "        m = re.search(pattern, s)\n",
    "        if m:\n",
    "            hp = float(m.group(1)); break\n",
    "    displacement = 0.0\n",
    "    for pattern in [r'(\\d+\\.?\\d*)\\s*L(?:\\s|$)', r'(\\d+\\.?\\d*)\\s*LITER']:\n",
    "        m = re.search(pattern, s)\n",
    "        if m:\n",
    "            displacement = float(m.group(1)); break\n",
    "    cyl = 0\n",
    "    for pattern in [r'(\\d+)\\s*CYLINDER', r'V(\\d+)', r'I(\\d+)']:\n",
    "        m = re.search(pattern, s)\n",
    "        if m:\n",
    "            cyl = int(m.group(1)); break\n",
    "    is_turbo = 1 if 'TURBO' in s else 0\n",
    "    is_supercharged = 1 if 'SUPERCHARGED' in s else 0\n",
    "    is_diesel = 1 if 'DIESEL' in s else 0\n",
    "    return hp, displacement, cyl, is_turbo, is_supercharged, is_diesel\n",
    "\n",
    "def create_text_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if 'model' in df.columns:\n",
    "        df['model_word_count'] = df['model'].fillna('').str.split().str.len()\n",
    "        df['model_has_numbers'] = df['model'].fillna('').str.contains(r'\\d', na=False).astype(int)\n",
    "        df['model_length'] = df['model'].fillna('').str.len()\n",
    "        premium_keywords = ['Limited', 'Premium', 'Sport', 'GT', 'AMG', 'M']\n",
    "        for keyword in premium_keywords:\n",
    "            df[f'model_has_{keyword.lower()}'] = df['model'].fillna('').str.contains(keyword, case=False, na=False).astype(int)\n",
    "    if 'transmission' in df.columns:\n",
    "        df['trans_speed'] = df['transmission'].fillna('').str.extract(r'(\\d+)').fillna(0).astype(int)\n",
    "        df['is_cvt'] = df['transmission'].fillna('').str.contains('CVT', case=False, na=False).astype(int)\n",
    "        df['is_4wd'] = df['transmission'].fillna('').str.contains('4WD|AWD', case=False, na=False).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_interaction_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    if {'car_age', 'milage'} <= set(df.columns):\n",
    "        df['age_mileage_ratio'] = df['milage'] / (df['car_age'] + 1)\n",
    "        df['log_mileage'] = np.log1p(df['milage'])\n",
    "        df['sqrt_mileage'] = np.sqrt(df['milage'])\n",
    "    if {'horsepower', 'car_age'} <= set(df.columns):\n",
    "        df['power_age_ratio'] = df['horsepower'] / (df['car_age'] + 1)\n",
    "    if 'model_year' in df.columns:\n",
    "        df['year_squared'] = df['model_year'] ** 2\n",
    "        df['years_since_2000'] = df['model_year'] - 2000\n",
    "        df['is_pre_2010'] = (df['model_year'] < 2010).astype(int)\n",
    "        df['is_post_2020'] = (df['model_year'] >= 2020).astype(int)\n",
    "    return df\n",
    "\n",
    "def advanced_feature_engineering_no_te(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Feature engineering that does not compute target encodings.\n",
    "    Use target encoding later in-fold to avoid leakage.\"\"\"\n",
    "    df = df.copy()\n",
    "    # year/age\n",
    "    if 'model_year' in df.columns:\n",
    "        df['car_age'] = CURRENT_YEAR - df['model_year']\n",
    "        df['car_age_squared'] = df['car_age'] ** 2\n",
    "        df['car_age_log'] = np.log1p(df['car_age'].clip(lower=0))\n",
    "        df['is_new_car'] = (df['car_age'] <= 2).astype(int)\n",
    "        df['is_old_car'] = (df['car_age'] >= 15).astype(int)\n",
    "        df['is_classic'] = (df['car_age'] >= 25).astype(int)\n",
    "    # mileage\n",
    "    if 'milage' in df.columns:\n",
    "        df['milage'] = df['milage'].fillna(df['milage'].median())\n",
    "        df['log_milage'] = np.log1p(df['milage'])\n",
    "        df['sqrt_milage'] = np.sqrt(df['milage'])\n",
    "        if 'car_age' in df.columns:\n",
    "            df['mileage_per_year'] = df['milage'] / np.maximum(df['car_age'], 0.5)\n",
    "            df['low_mileage_for_age'] = (df['mileage_per_year'] < 8000).astype(int)\n",
    "            df['high_mileage_for_age'] = (df['mileage_per_year'] > 15000).astype(int)\n",
    "        mileage_bins = [0, 15000, 50000, 100000, 150000, np.inf]\n",
    "        df['mileage_bin'] = pd.cut(df['milage'], bins=mileage_bins, labels=[0,1,2,3,4]).astype(int)\n",
    "        df['very_low_mileage'] = (df['milage'] < 15000).astype(int)\n",
    "        df['low_mileage'] = ((df['milage'] >= 15000) & (df['milage'] < 50000)).astype(int)\n",
    "        df['medium_mileage'] = ((df['milage'] >= 50000) & (df['milage'] < 100000)).astype(int)\n",
    "        df['high_mileage'] = ((df['milage'] >= 100000) & (df['milage'] < 150000)).astype(int)\n",
    "        df['very_high_mileage'] = (df['milage'] >= 150000).astype(int)\n",
    "    # engine\n",
    "    if 'engine' in df.columns:\n",
    "        eng = df['engine'].apply(extract_advanced_engine_features)\n",
    "        df['horsepower'] = [t[0] for t in eng]\n",
    "        df['engine_displacement'] = [t[1] for t in eng]\n",
    "        df['cylinders'] = [t[2] for t in eng]\n",
    "        df['is_turbo'] = [t[3] for t in eng]\n",
    "        df['is_supercharged'] = [t[4] for t in eng]\n",
    "        df['is_diesel_engine'] = [t[5] for t in eng]\n",
    "        df['hp_per_cylinder'] = np.where(df['cylinders'] > 0, df['horsepower'] / df['cylinders'], 0)\n",
    "        df['hp_per_liter'] = np.where(df['engine_displacement'] > 0, df['horsepower'] / df['engine_displacement'], 0)\n",
    "        for col in ['hp_per_cylinder', 'hp_per_liter', 'horsepower']:\n",
    "            if col in df.columns:\n",
    "                p99 = df[col].quantile(0.99)\n",
    "                df[col] = df[col].clip(0, p99)\n",
    "        df['is_high_performance'] = (df['horsepower'] > 300).astype(int)\n",
    "        df['is_economy'] = (df['horsepower'] < 150).astype(int)\n",
    "        df['engine_displacement'] = df['engine_displacement'].fillna(0).clip(lower=0)\n",
    "        engine_size_bins = [0, 1.5, 2.5, 3.5, 5.0, np.inf]\n",
    "        df['engine_size_category'] = pd.cut(df['engine_displacement'], bins=engine_size_bins, labels=[0,1,2,3,4], include_lowest=True).astype(int)\n",
    "    # brand/model/textual features\n",
    "    if 'brand' in df.columns:\n",
    "        df['brand'] = df['brand'].fillna('Unknown')\n",
    "        df['brand_frequency'] = df['brand'].map(df['brand'].value_counts()).fillna(1)\n",
    "    if 'model' in df.columns:\n",
    "        df['model'] = df['model'].fillna('Unknown')\n",
    "        df['model_popularity'] = df['model'].map(df['model'].value_counts()).fillna(1)\n",
    "        df['is_rare_model'] = (df['model_popularity'] < 5).astype(int)\n",
    "    if 'fuel_type' in df.columns:\n",
    "        df['fuel_type'] = df['fuel_type'].fillna('Gasoline')\n",
    "        fuel_efficiency = {'Electric':5, 'Hybrid':4, 'Diesel':3, 'Gasoline':2, 'E85 Flex Fuel':1.5}\n",
    "        df['fuel_efficiency_score'] = df['fuel_type'].map(fuel_efficiency).fillna(2)\n",
    "        df['is_electric'] = (df['fuel_type'] == 'Electric').astype(int)\n",
    "        df['is_hybrid'] = df['fuel_type'].str.contains('Hybrid', case=False, na=False).astype(int)\n",
    "    if 'transmission' in df.columns:\n",
    "        df['transmission'] = df['transmission'].fillna('Unknown')\n",
    "        df['is_automatic'] = df['transmission'].str.contains('A/T|Auto|CVT|Automatic', case=False, na=False).astype(int)\n",
    "        df['is_manual'] = df['transmission'].str.contains('Manual|M/T', case=False, na=False).astype(int)\n",
    "    if 'accident' in df.columns:\n",
    "        df['accident'] = df['accident'].fillna('None reported')\n",
    "        df['has_accident'] = (~df['accident'].str.contains('None|No', case=False, na=False)).astype(int)\n",
    "    if 'clean_title' in df.columns:\n",
    "        df['clean_title'] = df['clean_title'].fillna('Yes')\n",
    "        df['title_is_clean'] = (df['clean_title'] == 'Yes').astype(int)\n",
    "    if 'ext_col' in df.columns:\n",
    "        df['ext_col'] = df['ext_col'].fillna('Unknown')\n",
    "        popular_colors = {'White', 'Black', 'Silver', 'Gray', 'Grey'}\n",
    "        df['has_popular_color'] = df['ext_col'].isin(popular_colors).astype(int)\n",
    "    if 'int_col' in df.columns:\n",
    "        df['int_col'] = df['int_col'].fillna('Unknown')\n",
    "        luxury_interior = ['Leather', 'Premium']\n",
    "        df['has_luxury_interior'] = df['int_col'].str.contains('|'.join(luxury_interior), case=False, na=False).astype(int)\n",
    "\n",
    "    df = create_text_features(df)\n",
    "    df = create_interaction_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_target_encoding(train_series: pd.Series, target: pd.Series, apply_series: pd.Series,\n",
    "                           min_samples_leaf: int = 100, smoothing: float = 10.0) -> pd.Series:\n",
    "    \"\"\"Smoothed target encoding for a single categorical column.\n",
    "    Returns encoded values for apply_series based on statistics from train_series/target.\"\"\"\n",
    "    tmp = pd.concat([train_series, target], axis=1)\n",
    "    col_name = train_series.name\n",
    "    tmp.columns = [col_name, 'target']\n",
    "    agg = tmp.groupby(col_name)['target'].agg(['mean','count'])\n",
    "    prior = target.mean()\n",
    "    # smoothing factor\n",
    "    agg['smoothing'] = 1 / (1 + np.exp(-(agg['count'] - min_samples_leaf) / smoothing))\n",
    "    agg['te'] = prior * (1 - agg['smoothing']) + agg['mean'] * agg['smoothing']\n",
    "    mapping = agg['te'].to_dict()\n",
    "    return apply_series.map(mapping).fillna(prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_label_encoders(df: pd.DataFrame, cat_cols: List[str]) -> Dict[str, Dict]:\n",
    "    encoders = {}\n",
    "    for c in cat_cols:\n",
    "        vals = df[c].fillna('Unknown').astype(str).unique().tolist()\n",
    "        mapping = {v: i for i, v in enumerate(vals)}\n",
    "        encoders[c] = mapping\n",
    "    return encoders\n",
    "\n",
    "def apply_label_encoders(df: pd.DataFrame, encoders: Dict[str, Dict], cat_cols: List[str]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in cat_cols:\n",
    "        mapping = encoders.get(c, {})\n",
    "        df[c] = df[c].fillna('Unknown').astype(str).map(lambda x: mapping.get(x, -1)).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_models(random_state=SEED):\n",
    "    models = {\n",
    "        'lgb': lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.03, num_leaves=64, max_depth=10,\n",
    "                                 subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                                 random_state=random_state, n_jobs=-1, verbosity=-1),\n",
    "        'xgb': xgb.XGBRegressor(n_estimators=1000, learning_rate=0.03, max_depth=9,\n",
    "                                subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                                random_state=random_state, verbosity=0, n_jobs=-1),\n",
    "        'cat': CatBoostRegressor(iterations=1000, learning_rate=0.03, depth=8, l2_leaf_reg=3,\n",
    "                                 random_state=random_state, verbose=False),\n",
    "        'rf': RandomForestRegressor(n_estimators=500, max_depth=20, min_samples_split=5,\n",
    "                                    min_samples_leaf=2, max_features='sqrt', random_state=random_state, n_jobs=-1),\n",
    "        'et': ExtraTreesRegressor(n_estimators=500, max_depth=20, min_samples_split=5,\n",
    "                                  min_samples_leaf=2, max_features='sqrt', random_state=random_state, n_jobs=-1),\n",
    "        'ridge': Ridge(alpha=8.0, random_state=random_state)\n",
    "    }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Stacking Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedStacking:\n",
    "    def __init__(self, n_splits=5, random_state=SEED):\n",
    "        self.n_splits = n_splits\n",
    "        self.random_state = random_state\n",
    "        self.base_models = get_base_models(random_state)\n",
    "        self.fold_models = {k: [] for k in self.base_models.keys()}\n",
    "        self.meta_model = Ridge(alpha=1.0)\n",
    "        self.selected_features_union = None\n",
    "        # final encoders/scalers to be fitted on full train\n",
    "        self.full_label_encoders = {}\n",
    "        self.full_scaler = None\n",
    "        self.full_target_encodings = {}\n",
    "        self.final_base_models = {}\n",
    "\n",
    "    def fit(self, raw_train: pd.DataFrame, target_col: str = 'price'):\n",
    "        # raw_train includes price\n",
    "        X_raw = raw_train.drop(columns=[target_col]).reset_index(drop=True)\n",
    "        y = raw_train[target_col].reset_index(drop=True)\n",
    "        n = len(X_raw)\n",
    "        oof_preds = {name: np.zeros(n) for name in self.base_models.keys()}\n",
    "        selected_features_per_fold = []\n",
    "\n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=True, random_state=self.random_state)\n",
    "        fold_idx = 0\n",
    "        for train_idx, val_idx in kf.split(X_raw, y):\n",
    "            fold_idx += 1\n",
    "            print(f\"\\n=== Fold {fold_idx}/{self.n_splits} ===\")\n",
    "            X_train_raw = X_raw.loc[train_idx].reset_index(drop=True)\n",
    "            X_val_raw = X_raw.loc[val_idx].reset_index(drop=True)\n",
    "            y_train = y.loc[train_idx].reset_index(drop=True)\n",
    "            y_val = y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "            # Feature engineering without target encoding\n",
    "            X_train_fe = advanced_feature_engineering_no_te(X_train_raw)\n",
    "            X_val_fe = advanced_feature_engineering_no_te(X_val_raw)\n",
    "\n",
    "            # Target encoding brand and model (smooth) inside fold\n",
    "            if 'brand' in X_train_fe.columns:\n",
    "                X_train_fe['brand_te'] = smooth_target_encoding(X_train_fe['brand'], y_train, X_train_fe['brand'], min_samples_leaf=50, smoothing=10)\n",
    "                X_val_fe['brand_te'] = smooth_target_encoding(X_train_fe['brand'], y_train, X_val_fe['brand'], min_samples_leaf=50, smoothing=10)\n",
    "            else:\n",
    "                X_train_fe['brand_te'] = 0.0\n",
    "                X_val_fe['brand_te'] = 0.0\n",
    "\n",
    "            if 'model' in X_train_fe.columns:\n",
    "                # if model variety is huge smoothing helps\n",
    "                X_train_fe['model_te'] = smooth_target_encoding(X_train_fe['model'], y_train, X_train_fe['model'], min_samples_leaf=50, smoothing=10)\n",
    "                X_val_fe['model_te'] = smooth_target_encoding(X_train_fe['model'], y_train, X_val_fe['model'], min_samples_leaf=50, smoothing=10)\n",
    "            else:\n",
    "                X_train_fe['model_te'] = 0.0\n",
    "                X_val_fe['model_te'] = 0.0\n",
    "\n",
    "            # Drop large text columns we don't want as-is\n",
    "            drop_cols = ['engine', 'accident', 'clean_title']\n",
    "            for c in drop_cols:\n",
    "                if c in X_train_fe: X_train_fe.drop(columns=[c], inplace=True)\n",
    "                if c in X_val_fe: X_val_fe.drop(columns=[c], inplace=True)\n",
    "\n",
    "            # Identify categorical/object columns to label encode\n",
    "            cat_cols = X_train_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "            # Fit simple label encoders on train fold\n",
    "            fold_encoders = fit_label_encoders(X_train_fe, cat_cols)\n",
    "            X_train_enc = apply_label_encoders(X_train_fe, fold_encoders, cat_cols)\n",
    "            X_val_enc = apply_label_encoders(X_val_fe, fold_encoders, cat_cols)\n",
    "\n",
    "            # Ensure numeric columns exist and fill missing\n",
    "            num_cols = X_train_enc.select_dtypes(include=[np.number]).columns.tolist()\n",
    "            # Remove id/price if present\n",
    "            for c in ['id', 'price']:\n",
    "                if c in num_cols: num_cols.remove(c)\n",
    "\n",
    "            for c in num_cols:\n",
    "                fill = X_train_enc[c].median() if X_train_enc[c].nunique() > 10 else X_train_enc[c].mode().iloc[0] if len(X_train_enc[c].mode())>0 else 0\n",
    "                X_train_enc[c] = X_train_enc[c].fillna(fill)\n",
    "                X_val_enc[c] = X_val_enc[c].fillna(fill)\n",
    "\n",
    "            # Scale numeric features\n",
    "            scaler = RobustScaler()\n",
    "            X_train_enc[num_cols] = scaler.fit_transform(X_train_enc[num_cols])\n",
    "            X_val_enc[num_cols] = scaler.transform(X_val_enc[num_cols])\n",
    "\n",
    "            # Feature selection on train fold\n",
    "            k = min(120, X_train_enc.shape[1])\n",
    "            selector = SelectKBest(score_func=f_regression, k=k)\n",
    "            # need to supply y_train (use original y)\n",
    "            try:\n",
    "                sel_X_train = selector.fit_transform(X_train_enc, y_train)\n",
    "                sel_X_val = selector.transform(X_val_enc)\n",
    "                selected_mask = selector.get_support()\n",
    "                selected_cols = X_train_enc.columns[selected_mask].tolist()\n",
    "            except Exception as e:\n",
    "                # fallback: no selection\n",
    "                selected_cols = X_train_enc.columns.tolist()\n",
    "                sel_X_train = X_train_enc[selected_cols].values\n",
    "                sel_X_val = X_val_enc[selected_cols].values\n",
    "\n",
    "            selected_features_per_fold.append(selected_cols)\n",
    "            print(f\"Fold {fold_idx} selected {len(selected_cols)} features\")\n",
    "\n",
    "            # Train base models on log1p(y)\n",
    "            y_train_log = np.log1p(y_train)\n",
    "            for name, model in self.base_models.items():\n",
    "                print(f\" Training {name} on fold {fold_idx} ...\", end=\"\")\n",
    "                mdl = clone(model)\n",
    "                try:\n",
    "                    if name == 'lgb':\n",
    "                        mdl.fit(sel_X_train, y_train_log, eval_set=[(sel_X_val, np.log1p(y_val))],\n",
    "                                callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)])\n",
    "                    elif name == 'xgb':\n",
    "                        mdl.fit(sel_X_train, y_train_log, eval_set=[(sel_X_val, np.log1p(y_val))],\n",
    "                                early_stopping_rounds=50, verbose=False)\n",
    "                    elif name == 'cat':\n",
    "                        mdl.fit(sel_X_train, y_train_log, eval_set=(sel_X_val, np.log1p(y_val)),\n",
    "                                early_stopping_rounds=50, verbose=False)\n",
    "                    else:\n",
    "                        mdl.fit(sel_X_train, y_train_log)\n",
    "                except Exception as e:\n",
    "                    # fallback simple fit\n",
    "                    mdl = clone(model)\n",
    "                    mdl.fit(sel_X_train, y_train_log)\n",
    "\n",
    "                # store fold models for averaging later\n",
    "                self.fold_models[name].append((mdl, selected_cols, scaler, fold_encoders))\n",
    "                # Predict on validation (expm1 to revert log)\n",
    "                pred_val = np.expm1(mdl.predict(sel_X_val))\n",
    "                pred_val = np.maximum(pred_val, 0)\n",
    "                oof_preds[name][val_idx] = pred_val\n",
    "                print(\" done\")\n",
    "\n",
    "            # per-fold done\n",
    "\n",
    "        # After folds: compute OOF scores and prepare meta features\n",
    "        oof_df = pd.DataFrame(oof_preds)\n",
    "        oof_scores = {name: rmse(y.values, oof_df[name].values) for name in oof_df.columns}\n",
    "        for name, sc in oof_scores.items():\n",
    "            print(f\"OOF {name}: {sc:.6f}\")\n",
    "        # Train meta model (Ridge) on OOF predictions\n",
    "        print(\"\\nTraining meta-model (Ridge) on OOF predictions...\")\n",
    "        self.meta_model = Ridge(alpha=1.0)\n",
    "        self.meta_model.fit(oof_df.values, y.values)\n",
    "        meta_oof_pred = self.meta_model.predict(oof_df.values)\n",
    "        print(f\"Meta OOF RMSE: {rmse(y.values, meta_oof_pred):.6f}\")\n",
    "\n",
    "        # Determine union of selected features across folds\n",
    "        union_feats = sorted(set().union(*selected_features_per_fold))\n",
    "        self.selected_features_union = union_feats\n",
    "        print(f\"\\nUnion selected features count: {len(self.selected_features_union)}\")\n",
    "\n",
    "        # Fit full-train encoders / scalers / target encodings and final base models\n",
    "        print(\"\\nFitting final encoders, target encodings and base models on full train...\")\n",
    "        X_full_fe = advanced_feature_engineering_no_te(X_raw)\n",
    "        # compute target encodings on full train\n",
    "        if 'brand' in X_full_fe.columns:\n",
    "            X_full_fe['brand_te'] = smooth_target_encoding(X_full_fe['brand'], y, X_full_fe['brand'], min_samples_leaf=50, smoothing=10)\n",
    "            self.full_target_encodings['brand'] = X_full_fe[['brand','brand_te']].drop_duplicates().set_index('brand')['brand_te'].to_dict()\n",
    "        else:\n",
    "            self.full_target_encodings['brand'] = {}\n",
    "        if 'model' in X_full_fe.columns:\n",
    "            X_full_fe['model_te'] = smooth_target_encoding(X_full_fe['model'], y, X_full_fe['model'], min_samples_leaf=50, smoothing=10)\n",
    "            self.full_target_encodings['model'] = X_full_fe[['model','model_te']].drop_duplicates().set_index('model')['model_te'].to_dict()\n",
    "        else:\n",
    "            self.full_target_encodings['model'] = {}\n",
    "\n",
    "        for c in ['engine','accident','clean_title']:\n",
    "            if c in X_full_fe: X_full_fe.drop(columns=[c], inplace=True)\n",
    "\n",
    "        # full label encoders fitted on full train\n",
    "        cat_cols_full = X_full_fe.select_dtypes(include=['object']).columns.tolist()\n",
    "        self.full_label_encoders = fit_label_encoders(X_full_fe, cat_cols_full)\n",
    "        X_full_enc = apply_label_encoders(X_full_fe, self.full_label_encoders, cat_cols_full)\n",
    "\n",
    "        # add target enc columns if not present (they were added above)\n",
    "        # fill missing and scale\n",
    "        num_cols_full = X_full_enc.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        for c in ['id','price']:\n",
    "            if c in num_cols_full: num_cols_full.remove(c)\n",
    "        self.full_scaler = RobustScaler()\n",
    "        X_full_enc[num_cols_full] = self.full_scaler.fit_transform(X_full_enc[num_cols_full])\n",
    "\n",
    "        # ensure union features exist and take them\n",
    "        missing_feats = [c for c in self.selected_features_union if c not in X_full_enc.columns]\n",
    "        if missing_feats:\n",
    "            # create zero columns for missing features\n",
    "            for c in missing_feats:\n",
    "                X_full_enc[c] = 0.0\n",
    "        X_final_full = X_full_enc[self.selected_features_union].copy()\n",
    "\n",
    "        # Fit final base models on the entire training set (log1p target)\n",
    "        y_full_log = np.log1p(y.values)\n",
    "        for name, model in self.base_models.items():\n",
    "            print(f\" Fitting final {name} on full train...\", end=\"\")\n",
    "            mdl = clone(model)\n",
    "            try:\n",
    "                if name == 'lgb':\n",
    "                    mdl.fit(X_final_full.values, y_full_log, verbose=False)\n",
    "                elif name == 'xgb':\n",
    "                    mdl.fit(X_final_full.values, y_full_log, verbose=False)\n",
    "                elif name == 'cat':\n",
    "                    mdl.fit(X_final_full.values, y_full_log, verbose=False)\n",
    "                else:\n",
    "                    mdl.fit(X_final_full.values, y_full_log)\n",
    "            except Exception:\n",
    "                mdl = clone(model)\n",
    "                mdl.fit(X_final_full.values, y_full_log)\n",
    "            self.final_base_models[name] = mdl\n",
    "            print(\" done\")\n",
    "\n",
    "        # Optionally keep oof_df and y for inspection\n",
    "        self.oof_preds_df = oof_df\n",
    "        self.y_train = y.reset_index(drop=True)\n",
    "\n",
    "        return oof_scores\n",
    "\n",
    "    def predict(self, raw_test: pd.DataFrame) -> np.ndarray:\n",
    "        # raw_test is the test dataframe without price\n",
    "        X_test_raw = raw_test.reset_index(drop=True).copy()\n",
    "        X_test_fe = advanced_feature_engineering_no_te(X_test_raw)\n",
    "\n",
    "        # apply full-train target encodings to test\n",
    "        if 'brand' in X_test_fe.columns:\n",
    "            X_test_fe['brand_te'] = X_test_fe['brand'].map(self.full_target_encodings.get('brand', {})).fillna(self.y_train.mean())\n",
    "        else:\n",
    "            X_test_fe['brand_te'] = 0.0\n",
    "        if 'model' in X_test_fe.columns:\n",
    "            X_test_fe['model_te'] = X_test_fe['model'].map(self.full_target_encodings.get('model', {})).fillna(self.y_train.mean())\n",
    "        else:\n",
    "            X_test_fe['model_te'] = 0.0\n",
    "\n",
    "        for c in ['engine','accident','clean_title']:\n",
    "            if c in X_test_fe: X_test_fe.drop(columns=[c], inplace=True)\n",
    "\n",
    "        # label encode using full label encoders\n",
    "        cat_cols_full = list(self.full_label_encoders.keys())\n",
    "        X_test_enc = apply_label_encoders(X_test_fe, self.full_label_encoders, cat_cols_full)\n",
    "\n",
    "        # fill numeric na's and scale using full_scaler\n",
    "        num_cols = X_test_enc.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        for c in ['id','price']:\n",
    "            if c in num_cols:\n",
    "                num_cols.remove(c)\n",
    "        # ensure all scaler columns exist\n",
    "        for c in getattr(self.full_scaler, 'feature_names_in_', num_cols):\n",
    "            if c not in X_test_enc.columns:\n",
    "                X_test_enc[c] = 0.0\n",
    "        X_test_enc[num_cols] = self.full_scaler.transform(X_test_enc[num_cols])\n",
    "\n",
    "        # ensure selected features exist\n",
    "        missing_feats = [c for c in self.selected_features_union if c not in X_test_enc.columns]\n",
    "        for c in missing_feats:\n",
    "            X_test_enc[c] = 0.0\n",
    "\n",
    "        X_test_final = X_test_enc[self.selected_features_union].values\n",
    "\n",
    "        # get base model predictions (averaged single final models)\n",
    "        base_preds = {}\n",
    "        for name, mdl in self.final_base_models.items():\n",
    "            pred_log = mdl.predict(X_test_final)\n",
    "            pred = np.expm1(pred_log)\n",
    "            pred = np.maximum(pred, 0)\n",
    "            base_preds[name] = pred\n",
    "\n",
    "        base_preds_df = pd.DataFrame(base_preds)\n",
    "        # use meta-model to combine them\n",
    "        final_pred = self.meta_model.predict(base_preds_df.values)\n",
    "        final_pred = np.maximum(final_pred, 0)\n",
    "\n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed_everything(SEED)\n",
    "    print(\"Loading data...\")\n",
    "    train_df = pd.read_csv(\"/kaggle/input/dsn-car-price/train.csv\")\n",
    "    test_df = pd.read_csv(\"/kaggle/input/dsn-car-price/test.csv\")\n",
    "    sample_sub = pd.read_csv(\"/kaggle/input/dsn-car-price/sample_submission.csv\")\n",
    "\n",
    "    print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "    # Basic cleanup: ensure numeric columns are numeric\n",
    "    # If 'milage' spelled inconsistently adjust here\n",
    "    if 'milage' not in train_df.columns and 'mileage' in train_df.columns:\n",
    "        train_df.rename(columns={'mileage': 'milage'}, inplace=True)\n",
    "        test_df.rename(columns={'mileage': 'milage'}, inplace=True)\n",
    "\n",
    "    # Keep original price for later stats\n",
    "    print(\"\\nFeature engineering and training with proper CV...\")\n",
    "    trainer = ImprovedStacking(n_splits=N_SPLITS, random_state=SEED)\n",
    "    oof_scores = trainer.fit(train_df, target_col='price')\n",
    "\n",
    "    print(\"\\nMaking predictions on test set...\")\n",
    "    preds = trainer.predict(test_df)\n",
    "\n",
    "    # Post-processing on predictions\n",
    "    lower_bound = train_df['price'].quantile(0.005)\n",
    "    upper_bound = train_df['price'].quantile(0.995)\n",
    "    preds = np.clip(preds, lower_bound, upper_bound)\n",
    "    preds = np.maximum(preds, 1000)\n",
    "\n",
    "    print(\"\\nPrediction stats:\")\n",
    "    print(f\"Min: {preds.min():.0f}, Max: {preds.max():.0f}, Mean: {preds.mean():.0f}, Median: {np.median(preds):.0f}\")\n",
    "\n",
    "    submission = pd.DataFrame({'id': test_df['id'], 'Price': preds})\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Saved submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexicon": 6,
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
